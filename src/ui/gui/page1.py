from pathlib import Path
import json
import pandas as pd
import streamlit as st
from streamlit.runtime.uploaded_file_manager import UploadedFile

# --- æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from infra.config import PROJECT_ROOT, PathManager, DirNames
from model.patent import Patent
from ui.gui import query_detail
from ui.gui import ai_judge_detail
from ui.gui.search_results_list import search_results_list
from ui.gui.prior_art_detail import prior_art_detail

# å®šæ•°
MAX_CHAR = 300
EXCLUDE_DIRS = {
    DirNames.UPLOADED, DirNames.TOPK, "temp", DirNames.QUERY, DirNames.KNOWLEDGE,
    "__pycache__", ".git", ".ipynb_checkpoints"
}

def reset_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–"""
    keys_to_reset = [
        "df_retrieved", "matched_chunk_markdowns", "reasons",
        "query", "retrieved_docs", "search_results_df",
        "ai_judge_results", "file_content", "project_dir",
        "current_doc_number", "uploaded_dir"
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]

def load_project_by_id(doc_number: str) -> bool:
    """
    ã€å…±é€šå‡¦ç†ã€‘æŒ‡å®šã•ã‚ŒãŸ doc_number ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€SessionStateã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã‚‚ã€æ—¢å­˜é¸æŠæ™‚ã‚‚ã€æœ€çµ‚çš„ã«ã“ã‚Œã‚’å‘¼ã¶ã“ã¨ã§çŠ¶æ…‹ã‚’å¾©å…ƒã™ã‚‹ã€‚
    """
    # 1. ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
    reset_session_state()

    try:
        # --- A. åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ï¼ˆXML/Queryï¼‰ã®ãƒ­ãƒ¼ãƒ‰ ---
        uploaded_dir = PathManager.get_uploaded_query_path(doc_number)
        query_file = uploaded_dir / "uploaded_query.txt"

        if not query_file.exists():
            st.error(f"âŒ å‡ºé¡˜ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {query_file}")
            return False

        with open(query_file, "r", encoding="utf-8") as f:
            file_content = f.read()

        # XMLè§£æ
        query: Patent = st.session_state.loader.run(query_file)

        # åŸºæœ¬ã‚¹ãƒ†ãƒ¼ãƒˆè¨­å®š
        st.session_state.file_content = file_content
        st.session_state.query = query
        st.session_state.project_dir = uploaded_dir.parent
        st.session_state.uploaded_dir = uploaded_dir
        st.session_state.current_doc_number = doc_number

        # --- B. æ¤œç´¢çµæœï¼ˆCSVï¼‰ã®ãƒ­ãƒ¼ãƒ‰ (å­˜åœ¨ã™ã‚Œã°) ---
        topk_dir = PathManager.get_topk_results_path(doc_number)
        if topk_dir.exists():
            csv_files = sorted(topk_dir.glob("*.csv"))
            if csv_files:
                latest_csv = max(csv_files, key=lambda f: f.stat().st_mtime)
                search_results_df = pd.read_csv(latest_csv)
                st.session_state.search_results_df = search_results_df
                st.session_state.df_retrieved = search_results_df
                st.session_state.search_results_csv_path = str(latest_csv)

        # --- C. AIå¯©æŸ»çµæœï¼ˆJSONï¼‰ã®ãƒ­ãƒ¼ãƒ‰ (å­˜åœ¨ã™ã‚Œã°) ---
        ai_judge_dir = PathManager.get_ai_judge_result_path(doc_number)
        if ai_judge_dir.exists():
            json_files = sorted(ai_judge_dir.glob("*.json"))
            if json_files:
                latest_json = json_files[-1]
                with open(latest_json, 'r', encoding='utf-8') as f:
                    results = json.load(f)
                st.session_state.ai_judge_results = results

        return True

    except Exception as e:
        st.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ {doc_number} ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        st.code(traceback.format_exc())
        return False

def handle_new_upload(uploaded_file: UploadedFile):
    """æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®å‡¦ç†ï¼šä¿å­˜ã—ã¦IDã‚’ç‰¹å®šã—ã€å…±é€šãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å‘¼ã¶"""
    try:
        file_content = uploaded_file.read().decode("utf-8")

        # 1. ä¸€æ™‚ä¿å­˜ã—ã¦IDè§£æ (doc_numberã‚’å–å¾—ã™ã‚‹ãŸã‚)
        temp_path = PathManager.get_temp_path("uploaded_query.txt")
        with open(temp_path, "w", encoding="utf-8") as f:
            f.write(file_content)

        with st.spinner("XMLã‚’è§£æä¸­..."):
            query: Patent = st.session_state.loader.run(temp_path)
            doc_number = query.publication.doc_number

            if not doc_number:
                st.error("âŒ XMLã‹ã‚‰ç‰¹è¨±ç•ªå·(doc_number)ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

        # 2. æ­£è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ç§»å‹•ãƒ»ä¿å­˜
        PathManager.move_to_permanent(temp_path, doc_number)

        # 3. å…±é€šãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ãƒ‰ (ã“ã‚Œã§æ—¢å­˜ãƒ•ãƒ­ãƒ¼ã¨åˆæµ)
        if load_project_by_id(doc_number):
            st.success(f"âœ… æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆãƒ»ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {doc_number}")

    except UnicodeDecodeError:
        st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚UTF-8å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def page_1():
    st.title("GENIAC-PRIZE prototype")
    st.subheader("æ±äº¬å¤§å­¦æ¾å°¾å²©æ²¢ç ”ç©¶å®¤ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£")

    mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ("1. æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "2. æ—¢å­˜æ–‡çŒ®ã®è¡¨ç¤º"))

    # --- å…¥åŠ›ã‚¨ãƒªã‚¢ã®æç”» ---
    if mode == "1. æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        st.header("ğŸ“ æ–°è¦å‡ºé¡˜ã®å¯©æŸ»")
        uploaded_file = st.file_uploader("1. XMLå½¢å¼ã®å‡ºé¡˜ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xml", "txt"])

        if uploaded_file is not None:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ãŒã€ç¾åœ¨ãƒ­ãƒ¼ãƒ‰ä¸­ã®ã‚‚ã®ã¨é•ã†å ´åˆã®ã¿å‡¦ç†
            # (Streamlitã®ãƒªãƒ­ãƒ¼ãƒ‰å¯¾ç­–)
            current_content = st.session_state.get("file_content")

            # ã¾ã èª­ã¿è¾¼ã‚“ã§ã„ãªã„ã€ã‚ã‚‹ã„ã¯å†…å®¹ãŒå¤‰ã‚ã£ãŸå ´åˆã«å®Ÿè¡Œ
            # æ³¨: uploaded_file.getvalue()ãªã©ã§æ¯”è¼ƒã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚‹ãŒã€
            # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«æ—¢å­˜stateã®æœ‰ç„¡ã§åˆ¤å®šã—ã€ãƒœã‚¿ãƒ³ãªã—ã§å³æ™‚ãƒ­ãƒ¼ãƒ‰ã•ã›ã‚‹æŒ™å‹•ã‚’ç¶­æŒ
            if not current_content:
                 handle_new_upload(uploaded_file)
            else:
                 # ã™ã§ã«ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒåˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ãŸå ´åˆã®æ¤œçŸ¥ã¯
                 # file_uploaderã®keyã‚’å¤‰ãˆã‚‹ã‹ã€IDæ¯”è¼ƒãŒå¿…è¦ã ãŒã€ä»Šå›ã¯ç°¡æ˜“å®Ÿè£…ã¨ã™ã‚‹
                 st.info(f"ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {st.session_state.get('current_doc_number')}")

    else: # æ—¢å­˜æ–‡çŒ®ã®è¡¨ç¤º
        st.header("ğŸ“‚ æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å‚ç…§")

        eval_dir = PathManager.EVAL_DIR
        if eval_dir.exists():
            projects = [
                d.name for d in eval_dir.iterdir()
                if d.is_dir() and not d.name.startswith('.') and d.name not in EXCLUDE_DIRS
            ]
            projects.sort(reverse=True)

            col1, col2 = st.columns([3, 1])
            with col1:
                selected_doc = st.selectbox("å‡ºé¡˜IDã‚’é¸æŠã—ã¦ãã ã•ã„", projects)
            with col2:
                if st.button("èª­è¾¼", type="primary", use_container_width=True):
                    if selected_doc:
                        with st.spinner("ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                            if load_project_by_id(selected_doc):
                                st.success(f"âœ… {selected_doc} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # --- å…±é€šãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢æç”» ---
    # ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    if "query" in st.session_state and st.session_state.get("current_doc_number"):
        st.markdown("---")

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŸºæœ¬æƒ…å ±
        with st.expander(f"ğŸ“„ å‡ºé¡˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª: {st.session_state.current_doc_number}"):
            st.text_area("ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«", st.session_state.get("file_content", ""), height=150)

        # Step 2ä»¥é™ã®å…±é€šãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        render_common_steps()

    elif mode == "2. æ—¢å­˜æ–‡çŒ®ã®è¡¨ç¤º" and "query" in st.session_state and not st.session_state.get("current_doc_number"):
        st.warning("âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒç„¡åŠ¹ã§ã™ã€‚å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")


def render_common_steps():
    """
    Step 2ä»¥é™ã®å…±é€šå‡¦ç†
    ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã« st.session_state ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å‰æã§å‹•ä½œã™ã‚‹
    """

    # --- Step 2: é¡ä¼¼æ–‡çŒ®æ¤œç´¢ ---
    st.header("2. é¡ä¼¼æ–‡çŒ®ã®æ¤œç´¢")

    has_search_results = 'search_results_df' in st.session_state and st.session_state.search_results_df is not None

    if has_search_results:
        st.info(f"ï¿½ï¿½ æ¤œç´¢çµæœ: {len(st.session_state.search_results_df):,}ä»¶ å–å¾—æ¸ˆã¿")

        if st.button("ğŸ“‹ è©³ç´°ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º", key="goto_search_list"):
            if "æ¤œç´¢çµæœä¸€è¦§" in st.session_state.page_map:
                st.switch_page(st.session_state.page_map["æ¤œç´¢çµæœä¸€è¦§"])
            else:
                st.error("ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: æ¤œç´¢çµæœä¸€è¦§")
        if st.button("ğŸ”„ æ¤œç´¢ã‚’ã‚„ã‚Šç›´ã™", key="rerun_search"):
            query_detail.query_detail()
    else:
        st.write("Google Patents Public Dataã‚’ç”¨ã„ã¦é¡ä¼¼æ–‡çŒ®ã‚’æ¤œç´¢ã—ã¾ã™ã€‚")
        if st.button("æ¤œç´¢å®Ÿè¡Œ", type="primary", key="run_new_search"):
            query_detail.query_detail()

    # --- Step 3: AIå¯©æŸ» ---
    st.header("3. AIå¯©æŸ»")

    has_ai_results = 'ai_judge_results' in st.session_state and st.session_state.ai_judge_results

    if has_ai_results:
        # æœ‰åŠ¹ãªçµæœã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        valid_results = [r for r in st.session_state.ai_judge_results if r is not None and not (isinstance(r, dict) and 'error' in r)]

        if len(valid_results) == 0:
            st.warning("âš ï¸ AIå¯©æŸ»ã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚AIå¯©æŸ»ã‚’ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info(f"ğŸ’¾ å¯©æŸ»çµæœ: {len(valid_results)}ä»¶ å–å¾—æ¸ˆã¿")

            with st.expander("å¯©æŸ»çµæœä¸€è¦§ã‚’é–‹ã", expanded=True):
                display_idx = 1
                for idx, result in enumerate(st.session_state.ai_judge_results):

                    # result ãŒ None ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºãªã—ï¼‰
                    if result is None:
                        continue

                    # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºãªã—ï¼‰
                    if isinstance(result, dict) and 'error' in result:
                        continue

                    # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤º
                    doc_num = result.get('prior_art_doc_number', f"Doc #{display_idx}")
                    c1, c2 = st.columns([4, 1])
                    with c1:
                        st.write(f"**{display_idx}. {doc_num}**")
                    with c2:
                        if st.button("è©³ç´°", key=f"ai_detail_{idx}"):
                            st.session_state.selected_prior_art_idx = idx
                            if "å…ˆè¡ŒæŠ€è¡“è©³ç´°" in st.session_state.page_map:
                                st.switch_page(st.session_state.page_map["å…ˆè¡ŒæŠ€è¡“è©³ç´°"])
                            else:
                                st.error("ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: å…ˆè¡ŒæŠ€è¡“è©³ç´°")

                    display_idx += 1

        if st.button("ğŸ”„ AIå¯©æŸ»ã‚’ã‚„ã‚Šç›´ã™", type="primary", key="rerun_ai_judge"):
             run_ai_judge()
    else:
        st.write("LLMã‚’æ´»ç”¨ã—ã€æ–°è¦æ€§ãƒ»é€²æ­©æ€§ã‚’å¯©æŸ»ã—ã¾ã™ã€‚")
        if st.button("AIå¯©æŸ»å®Ÿè¡Œ", type="primary", key="run_ai_judge_new"):
            if not has_search_results:
                st.warning("âš ï¸ å…ˆã«ã€Œ2. é¡ä¼¼æ–‡çŒ®ã®æ¤œç´¢ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                run_ai_judge()

    # --- Step 4: åˆ¤æ–­æ ¹æ‹ å‡ºåŠ› ---
    st.header("4. åˆ¤æ–­æ ¹æ‹ å‡ºåŠ›")

    if not has_ai_results:
        st.write("âš ï¸ AIå¯©æŸ»ã‚’å®Ÿè¡Œã™ã‚‹ã¨è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    else:
        n_chunk_default = len(st.session_state.ai_judge_results)

        if st.button("æ ¹æ‹ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ", type="primary"):
            if "retrieved_docs" not in st.session_state or not st.session_state.retrieved_docs:
                 st.error("æ–‡çŒ®ãƒ‡ãƒ¼ã‚¿(retrieved_docs)ãŒãƒ¡ãƒ¢ãƒªã«ã‚ã‚Šã¾ã›ã‚“ã€‚å†æ¤œç´¢ãŒå¿…è¦ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            else:
                generate_reasons(n_chunk_default)

        if "reasons" in st.session_state and st.session_state.reasons:
            for i, reason in enumerate(st.session_state.reasons):
                st.markdown(f"##### åˆ¤æ–­æ ¹æ‹  {i + 1}")
                st.code(reason, language="markdown")


def run_ai_judge():
    """AIå¯©æŸ»å®Ÿè¡Œãƒ©ãƒƒãƒ‘ãƒ¼"""
    st.session_state.n_topk = len(st.session_state.df_retrieved)
    with st.spinner("å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œä¸­..."):
        results = ai_judge_detail.entry(action="button_click")
        if results:
            st.session_state.ai_judge_results = results
            st.success("âœ… AIå¯©æŸ»ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            st.rerun()

def generate_reasons(n_chunk):
    """æ ¹æ‹ ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯"""
    st.session_state.reasons = []
    status_text = st.empty()
    progress = st.progress(0)

    actual_limit = min(n_chunk, len(st.session_state.retrieved_docs))

    for i in range(actual_limit):
        status_text.text(f"{i + 1} / {actual_limit} ä»¶ç›®ã‚’ç”Ÿæˆä¸­ã§ã™...")
        if "generator" in st.session_state:
            reason = st.session_state.generator.generate(
                st.session_state.query,
                st.session_state.retrieved_docs[i]
            )
            st.session_state.reasons.append(reason)
        else:
            st.error("GeneratorãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            break
        progress.progress((i + 1) / actual_limit)

    status_text.text("ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    page_1()