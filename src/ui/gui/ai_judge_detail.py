import streamlit as st
from pathlib import Path
import pandas as pd
from llm.llm_data_loader import entry
import json

def display_single_result(result, idx):
    """
    å˜ä¸€ã®å…ˆè¡ŒæŠ€è¡“ã¨ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆè©³ç´°ãƒšãƒ¼ã‚¸ç”¨ï¼‰

    Args:
        result: å˜ä¸€ã®å¯©æŸ»çµæœ
        idx: å…ˆè¡ŒæŠ€è¡“ã®ç•ªå·ï¼ˆè¡¨ç¤ºç”¨ï¼‰
    """
    if isinstance(result, dict) and 'error' in result:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result['error']}")
        return

    st.markdown("---")
    st.markdown(f"## ğŸ” å…ˆè¡ŒæŠ€è¡“ #{idx + 1} ã¨ã®æ¯”è¼ƒ")
    st.markdown("---")

    # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†
    st.markdown("ğŸš€" * 40)
    st.markdown("### ç‰¹è¨±å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ (çµ±åˆç‰ˆ)")
    st.markdown("ğŸš€" * 40)

    # conversation_historyãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ä½¿ã£ã¦è¡¨ç¤º
    if 'conversation_history' in result and result['conversation_history']:
        for msg in result['conversation_history']:
            display_step_message(msg)
    else:
        # conversation_historyãŒãªã„å ´åˆã¯ã€å¾“æ¥ã®å½¢å¼ã§è¡¨ç¤º
        display_legacy_format(result)

    # æœ€çµ‚åˆ¤æ–­ã‚’å¼·èª¿è¡¨ç¤º
    if 'final_decision' in result:
        st.markdown("---")
        st.markdown("âœ…" * 40)
        st.markdown("### ç‰¹è¨±å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
        with st.chat_message("assistant", avatar="âš–ï¸"):
            st.markdown(result['final_decision'])
        st.markdown("âœ…" * 40)

    # é€²æ­©æ€§ã®åˆ¤æ–­çµæœã‚’ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    if 'inventiveness' in result:
        st.markdown("---")
        st.subheader("ğŸ“Š é€²æ­©æ€§åˆ¤æ–­ã‚µãƒãƒªãƒ¼")
        display_inventiveness_summary(result['inventiveness'])

def display_chat_messages(results):
    """
    LLMã®å‡ºåŠ›ã‚’é€æ¬¡ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§è¡¨ç¤ºã™ã‚‹

    Args:
        results: llm_entryã‹ã‚‰è¿”ã•ã‚ŒãŸå¯©æŸ»çµæœã®ãƒªã‚¹ãƒˆ
    """
    if not results:
        st.warning("å¯©æŸ»çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # å„å…ˆè¡ŒæŠ€è¡“ã¨ã®æ¯”è¼ƒçµæœã‚’è¡¨ç¤º
    for idx, result in enumerate(results):
        display_single_result(result, idx)

def display_step_message(msg):
    """
    å„ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§è¡¨ç¤º

    Args:
        msg: ã‚¹ãƒ†ãƒƒãƒ—æƒ…å ±ã‚’å«ã‚€è¾æ›¸ (step, role, content)
    """
    step = msg.get('step', '')
    role = msg.get('role', '')
    content = msg.get('content', '')

    # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚¢ãƒã‚¿ãƒ¼ã‚’è¨­å®š
    avatar_map = {
        'æ§‹é€ åŒ–': 'ğŸ“‹',
        'ä»£ç†äºº': 'âš–ï¸',
        'å¯©æŸ»å®˜': 'ğŸ”',
        'ä¸»ä»»å¯©æŸ»å®˜': 'âš–ï¸'
    }
    avatar = avatar_map.get(role, 'ğŸ’¬')

    # ã‚¹ãƒ†ãƒƒãƒ—ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("=" * 80)
    st.markdown(f"### {avatar} ã‚¹ãƒ†ãƒƒãƒ—{step}: {role}")
    st.markdown("=" * 80)

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’è¡¨ç¤º
    with st.chat_message("assistant", avatar=avatar):
        if isinstance(content, dict):
            # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            st.markdown("âœ… æ§‹é€ åŒ–å®Œäº†:")
            if 'problem' in content:
                st.markdown(f"**èª²é¡Œ:** {content['problem']}")
            if 'solution_principle' in content:
                st.markdown(f"**è§£æ±ºåŸç†:** {content['solution_principle']}")
            if 'claim1_requirements' in content:
                st.markdown(f"**Claim 1è¦ä»¶:** {len(content['claim1_requirements'])}å€‹")
                with st.expander("è¦ä»¶ã®è©³ç´°ã‚’è¡¨ç¤º"):
                    for req in content['claim1_requirements']:
                        st.markdown(f"- {req}")
        elif isinstance(content, str):
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
            st.markdown("âœ… ç”Ÿæˆå®Œäº†:")
            st.markdown("---")
            st.markdown(content)
            st.markdown("---")

def display_legacy_format(result):
    """
    conversation_historyãŒãªã„å ´åˆã®å¾“æ¥å½¢å¼ã§ã®è¡¨ç¤º

    Args:
        result: å¯©æŸ»çµæœã®è¾æ›¸
    """
    # æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–
    if 'application_structure' in result:
        st.markdown("=" * 80)
        st.markdown("### ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—0.1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–")
        st.markdown("=" * 80)
        with st.chat_message("assistant", avatar="ğŸ“‹"):
            st.json(result['application_structure'])

    # å…ˆè¡ŒæŠ€è¡“ã®æ§‹é€ åŒ–
    if 'prior_art_structure' in result:
        st.markdown("=" * 80)
        st.markdown("### ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—0.2: å…ˆè¡ŒæŠ€è¡“ã®æ§‹é€ åŒ–")
        st.markdown("=" * 80)
        with st.chat_message("assistant", avatar="ğŸ“‹"):
            st.json(result['prior_art_structure'])

    # ä»£ç†äººã®ä¸»å¼µ
    if 'applicant_arguments' in result:
        st.markdown("=" * 80)
        st.markdown("### âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: ä»£ç†äººã®æ®µéšçš„ä¸»å¼µ")
        st.markdown("=" * 80)
        with st.chat_message("assistant", avatar="âš–ï¸"):
            st.markdown(result['applicant_arguments'])

    # å¯©æŸ»å®˜ã®æ¤œè¨¼
    if 'examiner_review' in result:
        st.markdown("=" * 80)
        st.markdown("### ğŸ” ã‚¹ãƒ†ãƒƒãƒ—2: å¯©æŸ»å®˜ã®å°‚é–€çš„åˆ¤æ–­")
        st.markdown("=" * 80)
        with st.chat_message("assistant", avatar="ğŸ”"):
            st.markdown(result['examiner_review'])

    # æœ€çµ‚åˆ¤æ–­
    if 'final_decision' in result:
        st.markdown("=" * 80)
        st.markdown("### âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—3: ä¸»ä»»å¯©æŸ»å®˜ã®æ®µéšçš„çµ±åˆåˆ¤æ–­")
        st.markdown("=" * 80)
        with st.chat_message("assistant", avatar="âš–ï¸"):
            st.markdown(result['final_decision'])

def display_inventiveness_summary(inventiveness):
    """
    é€²æ­©æ€§åˆ¤æ–­ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º

    Args:
        inventiveness: é€²æ­©æ€§åˆ¤æ–­ã®è¾æ›¸
    """
    if 'error' in inventiveness:
        st.error("é€²æ­©æ€§ã®åˆ¤æ–­çµæœã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã«å¤‰æ›
    summary_data = []
    for claim_key, claim_data in inventiveness.items():
        if claim_key.startswith('claim'):
            inventive = claim_data.get('inventive', False)
            reason = claim_data.get('reason', '')
            summary_data.append({
                'ã‚¯ãƒ¬ãƒ¼ãƒ ': claim_key.upper(),
                'é€²æ­©æ€§': 'âœ… ã‚ã‚Š' if inventive else 'âŒ ãªã—',
                'ç†ç”±': reason
            })

    if summary_data:
        df = pd.DataFrame(summary_data)
        st.dataframe(df, use_container_width=True)

def ai_judge_detail(action="show_page"):
    """AIå¯©æŸ»çµæœã®è©³ç´°ç”»é¢"""
    st.title("ğŸ” AIç‰¹è¨±å¯©æŸ»ã®è©³ç´°çµæœ")

    with st.spinner("å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œä¸­..."):
        results = entry(action=action)

    # çµæœã‚’ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§è¡¨ç¤º
    display_chat_messages(results)
